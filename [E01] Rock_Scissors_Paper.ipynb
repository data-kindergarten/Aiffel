{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-ethiopia",
   "metadata": {},
   "source": [
    "# 프로젝트 : 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-difference",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-mustang",
   "metadata": {},
   "source": [
    "본 프로젝트는 과제 제출을 위해 최초 아이펠 구성원로부터 공유받은 이미지 데이터와 하이퍼파라미터를 조절을 통해 여러번에 걸쳐 테스트를 거쳤으나 정확도 수준이 45~60% 에서 계속 머물렀습니다.   \n",
    "그래서 __저조한 정확도에 대한 원인__이 __\"이미지의 다양성에 있지 않을까?\"__ 라는 생각을 하게 되었고, 가설에 대한 검증을 위해 __구글 텐서플로우에서 제공하는 가위바위보 데이터셋을 이용__ 하였고, 높은 정확도에 도달하였기 때문에 해당 데이터셋을 바탕으로 최종 프로젝트를 제출하였음을 미리 밝힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-chemistry",
   "metadata": {},
   "source": [
    "### 1-1. 데이터 만들기\n",
    "- 구글 teachable machine 사이트를 이용해 가위바위보 이미지 데이터를 만든다.\n",
    "- URL : https://teachablemachine.withgoogle.com/\n",
    "\n",
    "### 참고. 구글 텐서플로우 데이터셋\n",
    "- URL : https://www.tensorflow.org/datasets/catalog/rock_paper_scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-teens",
   "metadata": {},
   "source": [
    "### 1-2. 디렉토리 생성\n",
    "- 파일을 저장할 디렉토리를 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "recorded-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 만들기\n",
    "# mkdir - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "anonymous-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data 디렉토리\n",
    "# ~/aiffel/exploration/E01/train/rock\n",
    "# ~/aiffel/exploration/E01/train/scissors\n",
    "# ~/aiffel/exploration/E01/train/paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-communist",
   "metadata": {},
   "source": [
    "### 1-3. 이미지 업로드 및 압축해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "healthy-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 업로드\n",
    "# 쥬피터 노트북 이용(.zip 파일 드래그 앤 드롭)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cultural-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 압축 해제\n",
    "# 원하는 디렉토리 이동 : cd ~/aiffel/exploration/E01/train/rock\n",
    "# 압축 해제 명령어 : unzip 파일명.zip\n",
    "# 가위, 보에 대해서도 똑같이 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-utilization",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리(이미지 리사이징)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "celtic-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL(pillow) 라이브러리 사용\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "radical-anaheim",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이미지 사이즈 변경 함수 만들기\n",
    "\n",
    "def resize_images(img_path):\n",
    "    # glob.glob : 모든 png 파일을 읽어온다.\n",
    "    images=glob.glob(img_path + \"/*.png\")\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 이미지 사이즈를 모두 28x28 로 바꾸어 저장\n",
    "    target_size = (28,28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img)\n",
    "    \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "final-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839  images to be resized.\n",
      "839  images resized.\n",
      "가위 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고,\n",
    "#파일마다 모두 28x28 사이즈로 바꾸어 저장한다.'''\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/train/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "democratic-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n",
      "바위 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고,\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/train/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "presidential-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840  images to be resized.\n",
      "840  images resized.\n",
      "보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/train/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-holmes",
   "metadata": {},
   "source": [
    "## 3. train data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "renewable-delay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2519 입니다.\n",
      "x_train shape: (2519, 28, 28, 4)\n",
      "y_train shape: (2519,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load_data 함수 만들기\n",
    "def load_data(img_path):  \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2519 # 가위바위보 이미지 개수 총합에 주의\n",
    "    img_size=28\n",
    "    color=4\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels = np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path +'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/train\"\n",
    "(x_train, y_train) = load_data(image_dir_path)\n",
    "\n",
    "x_train_norm = x_train / 255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "committed-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨(정답)은:  0 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 불러온 이미지 샘플 확인하기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨(정답)은: ', y_train[0], '입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-clock",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네크워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "afraid-robinson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 16)        592       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,963\n",
      "Trainable params: 30,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model 생성\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 28x28 pixel의 컬러 이미지 파일에 대해 16개의 이미지 특징을 고려함\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,4)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "# 첫번째 이미지 특징 저장한 이후 32개의 이미지 특징을 고려함\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# 분류기의 알고리즘 복잡도 설정\n",
    "model.add(keras.layers.Dense(32, activation=\"relu\"))\n",
    "\n",
    "# 총 클래스의 개수 가위,바위,보 = 3가지\n",
    "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-metadata",
   "metadata": {},
   "source": [
    "## 5. 딥러닝 네크워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "loving-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1.0253 - accuracy: 0.5073\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.9159\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9818\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9939\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9958\n",
      "Epoch 6/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9985\n",
      "Epoch 7/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9996\n",
      "Epoch 8/8\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2176506c90>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "# 분류기의 학습횟수 설정\n",
    "model.fit(x_train_norm, y_train, epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-morris",
   "metadata": {},
   "source": [
    "## 6. test data로 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "banned-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 디렉토리 생성\n",
    "# mkdir -p ~/aiffel/exploration/E01/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "described-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  images to be resized.\n",
      "124  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고,\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "agreed-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  images to be resized.\n",
      "124  images resized.\n",
      "바위 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고,\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "stuck-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  images to be resized.\n",
      "124  images resized.\n",
      "보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 png 파일을 읽어들이고\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "earned-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터(x_test)의 이미지 개수는 372 입니다.\n",
      "x_test shape: (372, 28, 28, 4)\n",
      "y_test shape: (372,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path):  \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=372 # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=4\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path +'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/E01/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "modified-mongolia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨(정답)은:  0 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])\n",
    "print('라벨(정답)은: ', y_test[0], '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "revolutionary-change",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.3602 - accuracy: 0.8387\n",
      "test_loss: 0.3601795732975006 \n",
      "test_accuracy: 0.8387096524238586\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-ivory",
   "metadata": {},
   "source": [
    "## 7. 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-letter",
   "metadata": {},
   "source": [
    "### 1차 시도\n",
    "- 아이펠 동료 분들이 공유해주신 가위바위보 이미지 1500장을 train data, 내 데이터 300장을 test data로 활용해 최초 모델 정확도 평가를 진행하였다.  \n",
    "- 학습 데이터의 정확도는 98% 이상으로 높은 수치를 보였으나 test data를 통한 정확도는 33%에 불과 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-tulsa",
   "metadata": {},
   "source": [
    "### 2차 ~ n차 시도(10번 이상 반복한 것 같다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-brave",
   "metadata": {},
   "source": [
    "#### 1) 2차 시도\n",
    "- __\"학습 데이터의 양이 부족하여 정확도가 낮은 것이 아닐까\"__ 라는 생각이 들어 공유 해주신 모든 데이터를 내려받으니 __4500장__ 정도였다.  \n",
    "- test data도 데이터 퀄리티에 대한 의문이 생겨 아이펠 클라우드에서 기본으로 제공하고 있는 test data 300장을 가져와 활용하였다.  \n",
    "- 하이퍼파라미터도 계속해서 수치를 조정해가며 정확도를 높이기 위해 노력하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-supervision",
   "metadata": {},
   "source": [
    "#### 2) n차 시도(고민의 연속)  \n",
    "- 2차시도에서 정확도가 45% 정도 수준으로 10% 이상 상승하였으나, 그 이후 __45~59% 수준의 정확도__ 에서 정체되었다.\n",
    "- 하이퍼파라미터도 conv2d를 각각 512, 1024, dense도 1024까지 올려서 테스트를 진행하였는데. 정확도가 일시적으로 66%까지 상승하였으나 학습 시간이 너무 오래걸렸다.\n",
    "- 학습횟수(epochs)도 10~40회까지 다양하게 조정했는데, 횟수가 올라갈수록 오히려 train data의 학습 정확도가 떨어지는 현상이 발생하였다.\n",
    "- 결국, 하이퍼파라미터와 epochs를 늘리면 학습하는데 시간이 너무 오래 걸리는 문제와 모델의 정확도를 신뢰하기 힘들다고 판단하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-louis",
   "metadata": {},
   "source": [
    "### 최종 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-leonard",
   "metadata": {},
   "source": [
    "#### 1) 아지트 게시물에 올라온 교감쌤 댓글 힌트를 통해 생각의 전환을 시도 하였다.\n",
    "\n",
    "#### 2) 이미지의 퀄리티\n",
    "- 비단 이미지 뿐만 아니라 일반적인 데이터 분석을 할때도 데이터의 퀄리티는 매우 중요하다. 즉, 결측치나 이상치가 많으면 정확한 데이터 분석이 어렵기 때문에 전처리를 통해 데이터 퀄리티를 관리하는게 중요하다.\n",
    "- __기존에 공유 받은 이미지들은 다양성은 확보한 듯 보였으나 가위바위보의 뒷배경이 깔끔하지 않아 뒷배경이 깔끔한 이미지를 찾아보기로 했다.__\n",
    "\n",
    "#### 3) 이미지의 다양성\n",
    "- 구글에서 이미지를 찾아보던 중 텐서플로우에서 제공하는 가위바위보 데이터셋을 확인해보니 단순히 손 모양 뿐만 아니라 __피부색, 손톱의 색깔__ 등도 포함된 이미지를 제공하여 이미지의 다양을 더 확보할 수 있겠다는 생각이 들었다.\n",
    "\n",
    "#### 4) 테스트 결과\n",
    "- 구글 텐서플로우 가위바위보 데이터셋을 활용하여 모델 학습과 평가를 진행하였고 __최종 평가 정확도는 80~93% 수준으로 이전 데이터에 비해 아주 높은 정확도를 보여주었다.__\n",
    "\n",
    "#### 5) 아쉬웠던 점\n",
    "- 구글에서 제공한 데이터셋이 png 파일이였기 때문에 용량을 줄이고자 jpg 파일로 변환을 시도하였으나 거듭 실패하였다. 어떻게든 다시 해결해볼 예정이다.\n",
    "- 나 자신이나 동료들의 힘으로 직접 만든 데이터가 아닌 기본 제공 데이터로 최종 실험을 해서 나온 결과라는 점이 아쉽다.\n",
    "- 데이터 성능을 높일 수 있는 다른 방법을 시도해보지 못해 아쉽다.(텐서플로우를 활용한 이미지 증강을 사용한 조원도 있었는데 내가 코드를 이해하지 못해 따라하지 못했다.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
